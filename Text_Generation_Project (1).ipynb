{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwT4FsV8Z43l",
        "colab_type": "code",
        "outputId": "d2030a0f-377c-41bf-d276-96f97284750b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# importing dependencies\n",
        "import numpy\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi90h5AqeHlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading data\n",
        "file = open(\"84-0.txt\").read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQZVqnSueh_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenzing\n",
        "# standardizing\n",
        "def tokenize_words(input):\n",
        "  input = input.lower()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(input)\n",
        "  filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "  return \"\".join(filtered)\n",
        "\n",
        "processed_inputs = tokenize_words(file)  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OvKO-s7hwtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# chars to number\n",
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c,i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDJNrh2Ri-wy",
        "colab_type": "code",
        "outputId": "d4f9edcf-af3a-402f-d4c7-60c300e985b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if words to char and chars to num has worked\n",
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print(\"The total number of character: \" , input_len)\n",
        "print(\"Total vocab: \" , vocab_len)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total number of character:  233296\n",
            "Total vocab:  42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-ttbzmokH8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seq length\n",
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuhyWdEikazn",
        "colab_type": "code",
        "outputId": "3dd98a84-8b20-477a-e8ac-b35357b4afef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# loop through the sequence\n",
        "for i in range (0, input_len - seq_length, 1):\n",
        "  in_seq = processed_inputs[i:i + seq_length]\n",
        "  out_seq = processed_inputs[i + seq_length]\n",
        "  x_data.append([char_to_num[char] for char in in_seq])\n",
        "  y_data.append(char_to_num[out_seq])\n",
        "\n",
        "n_patterns = len(x_data)\n",
        "print (\"Total patterns: \", n_patterns)  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total patterns:  233196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S49ZbTYHmgzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert input sequence to np array and so on\n",
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X/float(vocab_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHTkjQIInk13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot encoding\n",
        "y = np_utils.to_categorical(y_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93qMk3rOn1kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phUeGadAp1QZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtxGmfdUs3ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving weights\n",
        "filepath = \"model_weights_saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "desired_callbacks = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytoP2q0It_oJ",
        "colab_type": "code",
        "outputId": "2fbe6e5f-29aa-48c9-881f-73407b199c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# fit model and let it train\n",
        "model.fit(X,y, epochs=4, batch_size=256, callbacks=desired_callbacks)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "233196/233196 [==============================] - 414s 2ms/step - loss: 2.9360\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.93596, saving model to model_weights_saved.hdf5\n",
            "Epoch 2/4\n",
            "233196/233196 [==============================] - 391s 2ms/step - loss: 2.9160\n",
            "\n",
            "Epoch 00002: loss improved from 2.93596 to 2.91600, saving model to model_weights_saved.hdf5\n",
            "Epoch 3/4\n",
            "233196/233196 [==============================] - 389s 2ms/step - loss: 2.9133\n",
            "\n",
            "Epoch 00003: loss improved from 2.91600 to 2.91328, saving model to model_weights_saved.hdf5\n",
            "Epoch 4/4\n",
            "233196/233196 [==============================] - 388s 2ms/step - loss: 2.8947\n",
            "\n",
            "Epoch 00004: loss improved from 2.91328 to 2.89470, saving model to model_weights_saved.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fb7b0280c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udus_-q3uuBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recompile model with saved weights\n",
        "filename = \"model_weights_saved.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwXmjue4Xj6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output of the model back into characters\n",
        "num_to_char = dict((i, c) for i, c in enumerate (chars))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acd-7_eOX-fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74c8c0ae-c1d8-4ae7-fe0c-dedd3bd0fc83"
      },
      "source": [
        "# random seed to help generate\n",
        "start = numpy.random.randint(0, len(x_data)-1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed: \")\n",
        "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed: \n",
            "\" avegreatestpleasurereceiveletteruncledatedparislongerformidabledistancemayhopeseelessfortnightpoorco \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mPljOajIzsa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74f8848a-1827-4fae-bdda-dbdb425fd77e"
      },
      "source": [
        "# generate the text\n",
        "for i in range (100):\n",
        "  x = numpy.reshape(pattern, (1,len(pattern), 1))\n",
        "  x = x/float(vocab_len)\n",
        "  prediction = model.predict(x, verbose =0)\n",
        "  index = numpy.argmax(prediction)\n",
        "  result = num_to_char[index]\n",
        "  seq_in = [num_to_char[value] for value in pattern]\n",
        "  sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)] "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7psBZRHDv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}